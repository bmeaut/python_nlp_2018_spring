{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory 04\n",
    "\n",
    "## 1. Comprehension\n",
    "\n",
    "Convert the following for loops into comprehensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(-5, 10, 2):\n",
    "    l.append(i-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(100):\n",
    "    if i % 10 == 4:\n",
    "        l.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [12, 1, 0, 13, -3, -4, 0, 2]\n",
    "l2 = []\n",
    "\n",
    "for e in l1:\n",
    "    if e % 2 == 1:\n",
    "        l2.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [12, 1, 0, 13, -3, -4, 0, 2]\n",
    "l2 = []\n",
    "\n",
    "for e in l1:\n",
    "    if e % 2 == 1:\n",
    "        l2.append(True)\n",
    "    else:\n",
    "        l2.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [3, 5, 7, 11, 13, 17, 19]\n",
    "l2 = [2, 4, 6, 8, 10]\n",
    "\n",
    "products = []\n",
    "\n",
    "for x in l1:\n",
    "    for y in l2:\n",
    "        products.append(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [3, 5, 7, 11, 13, 17, 19]\n",
    "l2 = [2, 4, 6, 8, 10]\n",
    "\n",
    "products = []\n",
    "\n",
    "for x in l1:\n",
    "    for y in l2:\n",
    "        if x + y % 3 == 0:\n",
    "            products.append(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\"apple\", \"plum\", \"pear\", \"avocado\"]\n",
    "\n",
    "mtx = []\n",
    "for fruit in fruits:\n",
    "    row = []\n",
    "    for i, c in enumerate(fruit):\n",
    "        row.append(c*(i+1))\n",
    "    mtx.append(row)\n",
    "    \n",
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ababaacdsadb\"\n",
    "\n",
    "char_freqs = {}\n",
    "\n",
    "for c in text:\n",
    "    try:\n",
    "        char_freqs[c] += 1\n",
    "    except KeyError:\n",
    "        char_freqs[c] = 1\n",
    "        \n",
    "char_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\"a\": 1, \"b\": 3, \"c\": 2}\n",
    "d2 = {\"a\": 2, \"b\": 1}\n",
    "\n",
    "d3 = {}\n",
    "\n",
    "for key in set(d1.keys()) | set(d2.keys()):\n",
    "    max_val = max(d1.get(key, 0), d2.get(key, 0))\n",
    "    d3[key] = max_val\n",
    "\n",
    "d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generators\n",
    "\n",
    "The following piece of code downloads a small sample of the Hungarian Webcorpus. We will work on this in later exercises.\n",
    "\n",
    "The corpus contains a single word-per-line and sentence boundaries are denoted by empty lines.\n",
    "\n",
    "The file has 4 columns separated by TABs:\n",
    "1. original word\n",
    "2. lemma (stemmed word)\n",
    "3. morphological analysis\n",
    "4. morphological analysis candidates.\n",
    "\n",
    "Take a look at the file before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "fn = 'web2-4p-9-17'\n",
    "zipname = fn + '.zip'\n",
    "\n",
    "if not os.path.exists(zipname):\n",
    "    print(\"Downloading corpus\")\n",
    "    webcorp_url = \"http://avalon.aut.bme.hu/~judit/resources/webcorp_parts/web2-4p-9-17.zip\"\n",
    "    u = urllib.request.URLopener()\n",
    "    u.retrieve(webcorp_url, zipname)\n",
    "\n",
    "if not os.path.exists(fn):\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile(zipname) as myzip:\n",
    "        myzip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Write a generator function that yields one sentence at a time as a list of tokens. Make sure to yield the very last sentence of the file as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(filename):\n",
    "    # TODO\n",
    "    \n",
    "sentence = next(read_sentences(fn))\n",
    "\n",
    "assert(len(sentence) == 19)\n",
    "assert isinstance(sentence, list)\n",
    "\n",
    "sentences = read_sentences(fn)\n",
    "\n",
    "assert isinstance(sentences, types.GeneratorType)\n",
    "\n",
    "sentences = list(sentences)\n",
    "\n",
    "assert(len(sentences) == 90764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Write a generator function that yields one sentence at a time but skips short sentences. The length limit should be a parameter of the generator which defaults to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_long_sentences(filename, min_length=5):\n",
    "    # TODO\n",
    "    \n",
    "sentences = read_long_sentences(fn)\n",
    "assert isinstance(sentences, types.GeneratorType)\n",
    "\n",
    "sentences = list(sentences)\n",
    "assert len(sentences) == 85163\n",
    "\n",
    "sentences = read_long_sentences(fn, 15)\n",
    "\n",
    "sentences = list(sentences)\n",
    "assert len(sentences) == 50059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Context managers\n",
    "\n",
    "Create a `Timer` context manager that measures the running time of the `with` block. The context manager takes an optional name argument and prints the block's name at the end too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    # TODO\n",
    "        \n",
    "        \n",
    "# prints \"slow code ran for F seconds\n",
    "# F is the total_seconds the block took to finish (float)\n",
    "with Timer(\"slow code\"):\n",
    "    s = sum(range(100000))\n",
    "    \n",
    "# prints \"unnamed ran for F seconds\n",
    "with Timer():\n",
    "    s = sum(range(100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extra exercise, binary search tree\n",
    "\n",
    "Create a binary search tree for integers. Write tests for your solution as well.\n",
    "\n",
    "Implement the following:\n",
    "- iteration protocol for the tree. Traversal should be in-order (increasing order).\n",
    "- sum(tree) - sum of all the elements\n",
    "- min(tree), max(tree) - smallest, largest element\n",
    "- len(tree) - number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
